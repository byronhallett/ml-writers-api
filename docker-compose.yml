version: '2.3'
services:
  traefik:
    image: traefik
    restart: always
    networks:
      - default
    ports:
      - "80:80"
      - "8085:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./traefik.toml:/traefik.toml

  blurb:
    runtime: nvidia
    restart: always
    image: asia.gcr.io/cl-syd-ml-writers/ml-api
    environment:
      - BUCKET_NAME=blurb-blocks
      - TEMPERATURE=0.9
      - BATCH_LENGTH=16
      - CUDA_VISIBLE_DEVICES=0
    entrypoint: "uwsgi --http 0.0.0.0:8000 --wsgi-file main.py --callable app --processes 2 --threads 2"
    volumes:
      - ./blurb:/gpt-2-server/model
    networks:
      - default
    ports:
      - "8000:8000"
    labels:
      - "traefik.enable=true"
      - "traefik.backend=machine-blurb"
      - "traefik.frontend.rule=PathPrefixStrip:/blurb"

  blurb-small-server:
    runtime: nvidia
    restart: always
    image: asia.gcr.io/cl-syd-ml-writers/ml-api
    environment:
      - BUCKET_NAME=blurb-blocks-small
      - TEMPERATURE=0.9
      - BATCH_LENGTH=16
      - CUDA_VISIBLE_DEVICES=1
    entrypoint: "uwsgi --http 0.0.0.0:8000 --wsgi-file main.py --callable app --processes 2 --threads 2"
    volumes:
      - ./blurb-small:/gpt-2-server/model
    networks:
      - default
    ports:
      - "8001:8000"
    labels:
      - "traefik.enable=true"
      - "traefik.backend=machine-blurb-small"
      - "traefik.frontend.rule=PathPrefixStrip:/blurb-small"

  stacked:
    runtime: nvidia
    restart: always
    image: asia.gcr.io/cl-syd-ml-writers/ml-api
    environment:
      - BUCKET_NAME=stacked-qa
      - TEMPERATURE=0.8
      - BATCH_LENGTH=32
      - CUDA_VISIBLE_DEVICES=2
    entrypoint: "uwsgi --http 0.0.0.0:8000 --wsgi-file main.py --callable app --processes 2 --threads 2"
    volumes:
      - ./stacked:/gpt-2-server/model
    networks:
      - default
    ports:
      - "8004:8000"
    labels:
      - "traefik.enable=true"
      - "traefik.backend=machine-stacked"
      - "traefik.frontend.rule=PathPrefixStrip:/stacked"

  life-sentence:
    runtime: nvidia
    restart: always
    image: asia.gcr.io/cl-syd-ml-writers/ml-api
    environment:
      - BUCKET_NAME=this-is-your-life
      - TEMPERATURE=0.9
      - BATCH_LENGTH=36
      - CUDA_VISIBLE_DEVICES=3
    entrypoint: "uwsgi --http 0.0.0.0:8000 --wsgi-file main.py --callable app --processes 2 --threads 2"
    volumes:
      - ./life-sentence:/gpt-2-server/model
    networks:
      - default
    ports:
      - "8006:8000"
    labels:
      - "traefik.enable=true"
      - "traefik.backend=machine-life-sentence"
      - "traefik.frontend.rule=PathPrefixStrip:/life-sentence"